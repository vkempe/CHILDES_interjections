---
title: "CHILDES interjections"
output:
  html_document:
    df_print: paged
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE)
```

```{r read libraries}
library(tidyverse)
library(childesr)
library(knitr)
library(lme4)
library(lmerTest)
library(ggeffects)
```

```{r read rds}
all_utterances_raw           <- readRDS("all_utterances_raw.rds")
all_interjections_both_clean <- readRDS("all_interjections_both_clean.rds")
all_speakers_data            <- readRDS("all_speakers_data.rds")
contingency_data             <- readRDS("contingency_data.rds")
contingent_interjections     <- readRDS("contingent_interjections.rds")
interjection_summary_clean   <- readRDS("interjection_summary_clean.rds")
english_corpora              <- readRDS("english_corpora.rds")
```


```{r extract interjections function, eval = FALSE}

extract_interjections <- function(gloss, pos) {
  words <- str_split(gloss, " ")[[1]]
  tags  <- str_split(pos,   " ")[[1]]
  if (length(words) != length(tags)) return(NA_character_)
  words[tags == "co"]
}

```


```{r extract utterances, eval = FALSE }
extract_all_utterances <- function(corpus_name) {
  message("Processing: ", corpus_name)
  tryCatch({
    utts <- get_utterances(corpus = corpus_name)
    
    utts %>%
      filter(!is.na(target_child_age),
             round(target_child_age) <= 72) %>%
      mutate(age_months = round(target_child_age),
             SpeakerType = if_else(speaker_code == "CHI", "CHI", "non-CHI")) %>%
      arrange(transcript_id, utterance_order) %>%
      group_by(transcript_id) %>%
      mutate(
        prev_speaker     = lag(speaker_code),
        prev_speakertype = lag(SpeakerType),
        has_co           = str_detect(part_of_speech, "\\bco\\b"),
        initial_co       = str_starts(part_of_speech, "co")
      ) %>%
      ungroup() %>%
      select(transcript_id, corpus_name, target_child_name,
             age_months, speaker_code, SpeakerType,
             utterance_order, gloss, part_of_speech,
             has_co, initial_co, prev_speaker, prev_speakertype)
  }, error = function(e) {
    message("Error in ", corpus_name, ": ", e$message)
    NULL
  })
}

all_utterances_raw <- map_dfr(english_corpora$corpus_name, extract_all_utterances)
```

```{r extract interjection tokens}
# Extract individual interjection tokens with utterance identifiers
all_interjections_raw <- all_utterances_raw %>%
  filter(has_co) %>%
  mutate(
    words = str_split(gloss, " "),
    tags  = str_split(part_of_speech, " "),
    interjection = map2(words, tags, ~ .x[.y == "co"]),
    # also get position of first co-tagged word
    first_co_word = map2_chr(words, tags, ~ {
      idx <- which(.y == "co")
      if (length(idx) > 0) .x[idx[1]] else NA_character_
    }),
    first_co_is_initial = str_starts(part_of_speech, "co")
  ) %>%
  unnest(interjection) %>%
  filter(!is.na(interjection)) %>%
  select(transcript_id, corpus_name, target_child_name,
         age_months, speaker_code, SpeakerType,
         utterance_order, interjection, first_co_word, first_co_is_initial)
```



```{r select interjections}

# Step 1: Consolidate spelling variants
all_interjections_raw <- all_interjections_raw %>%
  mutate(interjection = case_when(
    str_detect(interjection, "^[mh]+$")             ~ "mhm",
    interjection %in% c("uhhuh", "uhuh", "uhhum")  ~ "uhuh",
    interjection == "ahhah"                         ~ "aha",
    str_detect(interjection, "^u+h+m*$|^u+m+h*$")  ~ "um",
    str_detect(interjection, "^o+[hu]+m*$")         ~ "oh",
    str_detect(interjection, "^a+h+$")              ~ "ah",
    str_detect(interjection, "^hu+h*$")             ~ "huh",
    str_detect(interjection, "^u+h+o+h*$")          ~ "uh_oh",
    str_detect(interjection, "^o+ps+[ie]*$")        ~ "oops",
    str_detect(interjection, "^wo+w+$")             ~ "wow",
    str_detect(interjection, "^ye+a+h+$|^ya+h*$|^ye+h+$") ~ "yeah",
    str_detect(interjection, "^ye+s+$")             ~ "yes",
    str_detect(interjection, "^no+pe*$")            ~ "nope",
    str_detect(interjection, "^na+h+$")             ~ "nah",
    str_detect(interjection, "^sh+$")               ~ "shh",
    str_detect(interjection, "^e+w+$")              ~ "eww",
    str_detect(interjection, "^u+gh+$")             ~ "ugh",
    TRUE ~ interjection
  ))

# Also consolidate the first_co_word column the same way
all_interjections_raw <- all_interjections_raw %>%
  mutate(first_co_word = case_when(
    str_detect(first_co_word, "^[mh]+$")             ~ "mhm",
    first_co_word %in% c("uhhuh", "uhuh", "uhhum")  ~ "uhuh",
    first_co_word == "ahhah"                         ~ "aha",
    str_detect(first_co_word, "^u+h+m*$|^u+m+h*$")  ~ "um",
    str_detect(first_co_word, "^o+[hu]+m*$")         ~ "oh",
    str_detect(first_co_word, "^a+h+$")              ~ "ah",
    str_detect(first_co_word, "^hu+h*$")             ~ "huh",
    str_detect(first_co_word, "^u+h+o+h*$")          ~ "uh_oh",
    str_detect(first_co_word, "^o+ps+[ie]*$")        ~ "oops",
    str_detect(first_co_word, "^wo+w+$")             ~ "wow",
    str_detect(first_co_word, "^ye+a+h+$|^ya+h*$|^ye+h+$") ~ "yeah",
    str_detect(first_co_word, "^ye+s+$")             ~ "yes",
    str_detect(first_co_word, "^no+pe*$")            ~ "nope",
    str_detect(first_co_word, "^na+h+$")             ~ "nah",
    str_detect(first_co_word, "^sh+$")               ~ "shh",
    str_detect(first_co_word, "^e+w+$")              ~ "eww",
    str_detect(first_co_word, "^u+gh+$")             ~ "ugh",
    TRUE ~ first_co_word
  ))

# Step 2: Exclude non-interjections
exclude <- c(
  "right", "well", "so", "like", "alright", "okay", "you_know", "eh", "remember",
  "please", "sorry", "thank_you", "thanks",
  "look", "see", "say", "wait", "help",
  "my", "silly", "careful",
  "yyy"
)

# Step 3: Frequency table and whitelist
intj_freq <- all_interjections_raw %>%
  filter(!interjection %in% exclude) %>%
  count(interjection, sort = TRUE) %>%
  mutate(prop = n / sum(n),
         cum_prop = cumsum(prop))

intj_freq %>% print(n = 50)

whitelist <- intj_freq %>%
  filter(cum_prop <= 0.90 | lag(cum_prop, default = 0) < 0.90) %>%
  pull(interjection)

whitelist

# Step 4: Clean token-level data
all_interjections_both_clean <- all_interjections_raw %>%
  filter(interjection %in% whitelist)

# Step 5: Clean contingent interjections
contingent_interjections <- all_interjections_raw %>%
  filter(first_co_is_initial,
         first_co_word %in% whitelist,
         interjection %in% whitelist)
```


```{r aggregate }
# Utterances that contain at least one whitelisted interjection
clean_has_co <- all_interjections_both_clean %>%
  distinct(transcript_id, utterance_order) %>%
  mutate(has_co_clean = TRUE)

# Utterances where the first co-tagged word is whitelisted
clean_initial_co <- all_interjections_raw %>%
  filter(first_co_is_initial, first_co_word %in% whitelist) %>%
  distinct(transcript_id, utterance_order) %>%
  mutate(initial_co_clean = TRUE)

# Attach cleaned flags to utterances
all_utterances_clean <- all_utterances_raw %>%
  left_join(clean_has_co, by = c("transcript_id", "utterance_order")) %>%
  left_join(clean_initial_co, by = c("transcript_id", "utterance_order")) %>%
  mutate(has_co_clean = replace_na(has_co_clean, FALSE),
         initial_co_clean = replace_na(initial_co_clean, FALSE))

# Session-level summary
all_speakers_data <- all_utterances_clean %>%
  group_by(transcript_id) %>%
  mutate(session_length = n()) %>%
  ungroup() %>%
  group_by(transcript_id, corpus_name, target_child_name,
           age_months, SpeakerType) %>%
  summarise(
    total_utterances = n(),
    n_interjections  = sum(has_co_clean),
    session_length   = first(session_length),
    .groups = "drop"
  ) %>%
  mutate(PropIntrj = n_interjections / total_utterances)

# Contingency summary
contingency_data <- all_utterances_clean %>%
  filter(
    (SpeakerType == "non-CHI" & prev_speakertype == "CHI") |
    (SpeakerType == "CHI"     & prev_speakertype %in% c("CHI", "non-CHI"))
  ) %>%
  group_by(transcript_id) %>%
  mutate(session_length = n()) %>%
  ungroup() %>%
  group_by(transcript_id, corpus_name, target_child_name,
           age_months, SpeakerType) %>%
  summarise(
    total_utterances = n(),
    n_initial_co     = sum(initial_co_clean),
    session_length   = first(session_length),
    .groups = "drop"
  ) %>%
  mutate(PropIntrj = n_initial_co / total_utterances)

# Caregiver summary
interjection_summary_clean <- all_speakers_data %>%
  filter(SpeakerType == "non-CHI") %>%
  rename(proportion = PropIntrj)
```



```{r save all rds, eval=FALSE}
saveRDS(all_utterances_raw,           "all_utterances_raw.rds")
saveRDS(all_interjections_both_clean, "all_interjections_both_clean.rds")
saveRDS(all_speakers_data,            "all_speakers_data.rds")
saveRDS(contingency_data,             "contingency_data.rds")
saveRDS(contingent_interjections,     "contingent_interjections.rds")
saveRDS(interjection_summary_clean,   "interjection_summary_clean.rds")
saveRDS(english_corpora,              "english_corpora.rds")
```


```{r total proportion of interjections}
interjection_summary_clean %>%
  filter(!is.na(age_months), age_months <= 72) %>%
  summarise(
    total_interjections = sum(n_interjections),
    total_utterances = sum(total_utterances),
    proportion = total_interjections / total_utterances
  )
```

#Analyses from here

```{r plot interjections by main caregiver}
role_codes <- c("MOT", "FAT", "DAD", "MOM", "INV", "SIS", "BRO", 
                "GRA", "GMA", "AUN", "UNC")

interlocutor_plot <- all_utterances_clean %>%
  filter(!is.na(age_months), age_months <= 72,
         SpeakerType == "non-CHI",
         speaker_code %in% role_codes) %>%
  mutate(speaker_code = recode(speaker_code, 
                                "DAD" = "FAT", 
                                "MOM" = "MOT")) %>%
  group_by(transcript_id, corpus_name, target_child_name,
           age_months, speaker_code) %>%
  summarise(
    total_utterances = n(),
    n_interjections  = sum(has_co_clean, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(PropIntrj = n_interjections / total_utterances) %>%
  group_by(speaker_code) %>%
  summarise(
    mean_proportion  = mean(PropIntrj),
    se               = sd(PropIntrj) / sqrt(n()),
    n_sessions       = n(),
    n_utterances     = sum(total_utterances),
    .groups = "drop"
  ) %>%
  arrange(desc(mean_proportion))

ggplot(interlocutor_plot, 
       aes(x = reorder(speaker_code, mean_proportion), 
           y = mean_proportion)) +
  geom_col(fill = "#2dd4bf", alpha = 0.8) +
  geom_errorbar(aes(ymin = mean_proportion - se, 
                    ymax = mean_proportion + se),
                width = 0.3, colour = "white") +
  geom_text(aes(label = paste0("n=", scales::comma(n_utterances))), 
            hjust = -0.2, size = 3, colour = "grey60") +
  coord_flip() +
  scale_y_continuous("Mean proportion of turns with interjection",
                     limits = c(0, 0.45)) +
  scale_x_discrete("Interlocutor") +
  theme_minimal(base_size = 13) +
  labs(title = "Caregiver interjection use by interlocutor",
       subtitle = "Children aged 0-72 months, English CHILDES corpora")
```


```{r regression models total turns with interjections }
# Fit model
all_speakers_data <- all_speakers_data %>%
  mutate(age_c = age_months - mean(age_months, na.rm = TRUE),
         session_length_s = scale(session_length))

model_quad <- lmer(PropIntrj ~ SpeakerType * poly(age_c, 3) + session_length_s + 
                     (1 | corpus_name/target_child_name), 
                   data = all_speakers_data)

summary(model_quad)

all_speakers_data <- all_speakers_data %>%
  mutate(SpeakerType = relevel(factor(SpeakerType), ref = "non-CHI"))

model_quad_releveled <- lmer(PropIntrj ~ SpeakerType * poly(age_c, 3) + session_length_s + 
                     (1 | corpus_name/target_child_name), 
                   data = all_speakers_data)

summary(model_quad_releveled)
```



```{r plot raw proportion of interjections by age and speaker type}
ggplot(all_speakers_data, 
       aes(x = age_months, y = PropIntrj, colour = SpeakerType)) +
  geom_point(alpha = 0.1, size = 0.3) +
  geom_smooth(method = "loess", se = TRUE, linewidth = 1.2) +
  scale_colour_manual(values = c("CHI" = "red", "non-CHI" = "blue")) +
  scale_x_continuous("Child age (months)") +
  scale_y_continuous("Proportion of turns with interjection") +
  theme_minimal(base_size = 13) +
  labs(title = "Interjection use by speaker type across development",
       subtitle = "English CHILDES corpora, 0-72 months",
       colour = "Speaker")
```

```{r plot model-estimated proportions of interjections}

pred <- ggpredict(model_quad, terms = c("age_c [all]", "SpeakerType"))

mean_age <- mean(all_speakers_data$age_months, na.rm = TRUE)
pred$age_months <- pred$x + mean_age

ggplot(all_speakers_data, aes(x = age_months, y = PropIntrj, colour = SpeakerType)) +
  geom_smooth(method = "loess", se = FALSE, linetype = "dashed", alpha = 0.3) +
  geom_line(data = pred, aes(x = age_months, y = predicted, colour = group), 
            inherit.aes = FALSE, linewidth = 1) +
  geom_ribbon(data = pred, aes(x = age_months, ymin = conf.low, ymax = conf.high, fill = group), 
              inherit.aes = FALSE, alpha = 0.2) +
  scale_colour_manual(name = "Speaker", values = c("CHI" = "red", "non-CHI" = "blue")) +
scale_fill_manual(name = "Speaker", values = c("CHI" = "red", "non-CHI" = "blue")) +
  theme_minimal(base_size = 13) +
  theme(plot.title = element_text(size = 11),
      plot.subtitle = element_text(size = 10)) +
  labs(x = "Age (months)", y = "Proportion interjections",
       title = "Model-estimated interjection use by speaker type across development",
       subtitle = "English CHILDES corpora before 2021, 0-72 months")

```


```{r 10 top interjections for adults and children}
# Get top 10 overall across both speaker types combined
top10_overall <- all_interjections_both_clean %>%
  filter(!is.na(age_months), age_months <= 72) %>%
  count(interjection, sort = TRUE) %>%
  slice_head(n = 10) %>%
  pull(interjection)

# Get counts for those interjections by speaker type
top10_combined <- all_interjections_both_clean %>%
  filter(!is.na(age_months), age_months <= 72,
         interjection %in% top10_overall) %>%
  mutate(SpeakerType = if_else(speaker_code == "CHI", "CHI", "non-CHI")) %>%
  group_by(SpeakerType, interjection) %>%
  summarise(n = n(), .groups = "drop")

ggplot(top10_combined,
       aes(x = reorder(interjection, n), y = n, fill = SpeakerType)) +
  geom_col(position = "dodge") +
  coord_flip() +
  scale_fill_manual(values = c("CHI" = "red", "non-CHI" = "blue")) +
  scale_y_continuous(labels = scales::comma) +
  xlab("Interjection") +
  ylab("Number of tokens") +
  theme_minimal(base_size = 13) +
  labs(title = "Top 10 interjections by speaker type",
       subtitle = "Children aged 0-72 months, English CHILDES corpora",
       fill = "Speaker")
```

```{r regression models contingent interjections}

# Fit model
contingency_data <- contingency_data %>%
  mutate(age_c = age_months - mean(age_months, na.rm = TRUE),
         session_length_s = scale(session_length))

model_contingency_quad <- lmer(PropIntrj ~ SpeakerType * poly(age_c, 3) + session_length_s + 
                     (1 | corpus_name/target_child_name), 
                   data = contingency_data)

summary(model_contingency_quad)

contingency_data <- contingency_data %>%
  mutate(SpeakerType = relevel(factor(SpeakerType), ref = "non-CHI"))

model_contingency_quad_releveled <- lmer(PropIntrj ~ SpeakerType * poly(age_c, 3) + session_length_s + 
                     (1 | corpus_name/target_child_name), 
                   data = contingency_data)

summary(model_contingency_quad_releveled)

```


```{r plot contingent interjections}
ggplot(contingency_data, 
       aes(x = age_months, y = PropIntrj, colour = SpeakerType)) +
  geom_point(alpha = 0.1, size = 0.3) +
  geom_smooth(method = "loess", se = TRUE, linewidth = 1.2) +
  scale_colour_manual(values = c("CHI" = "red", "non-CHI" = "blue")) +
  scale_x_continuous("Child age (months)") +
  scale_y_continuous("Proportion of contingent interjections") +
  theme_minimal(base_size = 13) +
  labs(title = "Turn-initial interjections following child utterances",
       subtitle = "English CHILDES corpora, 0-72 months",
       colour = "Speaker")
```

```{r plot model-estimated proportions of contingent interjections}

pred <- ggpredict(model_contingency_quad, terms = c("age_c [all]", "SpeakerType"))

mean_age <- mean(contingency_data$age_months, na.rm = TRUE)
pred$age_months <- pred$x + mean_age

ggplot(contingency_data, aes(x = age_months, y = PropIntrj, colour = SpeakerType)) +
  geom_smooth(method = "loess", se = FALSE, linetype = "dashed", alpha = 0.3) +
  geom_line(data = pred, aes(x = age_months, y = predicted, colour = group), 
            inherit.aes = FALSE, linewidth = 1) +
  geom_ribbon(data = pred, aes(x = age_months, ymin = conf.low, ymax = conf.high, fill = group), 
              inherit.aes = FALSE, alpha = 0.2) +
 scale_colour_manual(name = "Speaker", values = c("CHI" = "red", "non-CHI" = "blue")) +
scale_fill_manual(name = "Speaker", values = c("CHI" = "red", "non-CHI" = "blue")) +
  theme_minimal(base_size = 13) +
  theme(plot.title = element_text(size = 11),
      plot.subtitle = element_text(size = 10)) +
  scale_y_continuous(limits = c(NA, 0.4)) +
  labs(x = "Age (months)", y = "Proportion contingent interjections",
       title = "Model-estimated contingent interjection use by speaker type across development",
       subtitle = "English CHILDES corpora before 2021, 0-72 months")

```



```{r plot top 10 contingency interjections}
# Top 10 overall
top10_contingency <- contingent_interjections %>%
  filter(!is.na(age_months), age_months <= 72) %>%
  count(interjection, sort = TRUE) %>%
  slice_head(n = 10) %>%
  pull(interjection)

# Counts by speaker type
top10_contingency_combined <- contingent_interjections %>%
  filter(!is.na(age_months), age_months <= 72,
         interjection %in% top10_contingency) %>%
  group_by(SpeakerType, interjection) %>%
  summarise(n = n(), .groups = "drop")

ggplot(top10_contingency_combined,
       aes(x = reorder(interjection, n), y = n, fill = SpeakerType)) +
  geom_col(position = "dodge") +
  coord_flip() +
  scale_fill_manual(values = c("CHI" = "red", "non-CHI" = "blue")) +
  scale_y_continuous(labels = scales::comma) +
  xlab("Interjection") +
  ylab("Number of tokens") +
  theme_minimal(base_size = 13) +
  labs(title = "Top 10 contingent interjections by speaker type",
       subtitle = "Children aged 0-72 months, English CHILDES corpora",
       fill = "Speaker")
```
Elmlinger et al. (2019) showed that caregivers' contingent responses to children are simpler and more repetitive than non-contingent speech. A turn-initial interjection is about as simple as it gets â€” it's a single minimal response token that acknowledges the child's utterance before anything else.
Nearly 18% all caregiver responses to children open with an interjection. That fits perfectly with the Elmlinger framework and also connects to the robot application: if the robot needs processing time after a child utterance, deploying a turn-initial interjection like oh or yeah is exactly what a human caregiver would do in that position.
