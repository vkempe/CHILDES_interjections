---
title: "CHILDES interjections"
output:
  html_document:
    df_print: paged
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE)
```

```{r read libraries}
library(tidyverse)
library(childesr)
library(knitr)
library(lme4)
library(lmerTest)
library(ggeffects)
```

```{r read rds}
all_utterances_raw           <- readRDS("all_utterances_raw.rds")
all_interjections_both_clean <- readRDS("all_interjections_both_clean.rds")
all_speakers_data            <- readRDS("all_speakers_data.rds")
contingency_data             <- readRDS("contingency_data.rds")
contingent_interjections     <- readRDS("contingent_interjections.rds")
interjection_summary_clean   <- readRDS("interjection_summary_clean.rds")
english_corpora              <- readRDS("english_corpora.rds")
```


```{r extract interjections function, eval = FALSE}

extract_interjections <- function(gloss, pos) {
  words <- str_split(gloss, " ")[[1]]
  tags  <- str_split(pos,   " ")[[1]]
  if (length(words) != length(tags)) return(NA_character_)
  words[tags == "co"]
}

```


```{r extract utterances, eval = FALSE }
extract_all_utterances <- function(corpus_name) {
  message("Processing: ", corpus_name)
  tryCatch({
    utts <- get_utterances(corpus = corpus_name)
    
    utts %>%
      filter(!is.na(target_child_age),
             round(target_child_age) <= 72) %>%
      mutate(age_months = round(target_child_age),
             SpeakerType = if_else(speaker_code == "CHI", "CHI", "non-CHI")) %>%
      arrange(transcript_id, utterance_order) %>%
      group_by(transcript_id) %>%
      mutate(
        prev_speaker     = lag(speaker_code),
        prev_speakertype = lag(SpeakerType),
        has_co           = str_detect(part_of_speech, "\\bco\\b"),
        initial_co       = str_starts(part_of_speech, "co")
      ) %>%
      ungroup() %>%
      select(transcript_id, corpus_name, target_child_name,
             age_months, speaker_code, SpeakerType,
             utterance_order, gloss, part_of_speech,
             has_co, initial_co, prev_speaker, prev_speakertype)
  }, error = function(e) {
    message("Error in ", corpus_name, ": ", e$message)
    NULL
  })
}

all_utterances_raw <- map_dfr(english_corpora$corpus_name, extract_all_utterances)
```

```{r extract interjection tokens}
# Extract individual interjection tokens with utterance identifiers
all_interjections_raw <- all_utterances_raw %>%
  filter(has_co) %>%
  mutate(
    words = str_split(gloss, " "),
    tags  = str_split(part_of_speech, " "),
    interjection = map2(words, tags, ~ .x[.y == "co"]),
    # also get position of first co-tagged word
    first_co_word = map2_chr(words, tags, ~ {
      idx <- which(.y == "co")
      if (length(idx) > 0) .x[idx[1]] else NA_character_
    }),
    first_co_is_initial = str_starts(part_of_speech, "co")
  ) %>%
  unnest(interjection) %>%
  filter(!is.na(interjection)) %>%
  select(transcript_id, corpus_name, target_child_name,
         age_months, speaker_code, SpeakerType,
         utterance_order, interjection, first_co_word, first_co_is_initial)
```



```{r select interjections}

# Step 1: Consolidate spelling variants
all_interjections_raw <- all_interjections_raw %>%
  mutate(interjection = case_when(
    str_detect(interjection, "^[mh]+$")             ~ "mhm",
    interjection %in% c("uhhuh", "uhuh", "uhhum")  ~ "uhuh",
    interjection == "ahhah"                         ~ "aha",
    str_detect(interjection, "^u+h+m*$|^u+m+h*$")  ~ "um",
    str_detect(interjection, "^o+[hu]+m*$")         ~ "oh",
    str_detect(interjection, "^a+h+$")              ~ "ah",
    str_detect(interjection, "^hu+h*$")             ~ "huh",
    str_detect(interjection, "^u+h+o+h*$")          ~ "uh_oh",
    str_detect(interjection, "^o+ps+[ie]*$")        ~ "oops",
    str_detect(interjection, "^wo+w+$")             ~ "wow",
    str_detect(interjection, "^ye+a+h+$|^ya+h*$|^ye+h+$") ~ "yeah",
    str_detect(interjection, "^ye+s+$")             ~ "yes",
    str_detect(interjection, "^no+pe*$")            ~ "nope",
    str_detect(interjection, "^na+h+$")             ~ "nah",
    str_detect(interjection, "^sh+$")               ~ "shh",
    str_detect(interjection, "^e+w+$")              ~ "eww",
    str_detect(interjection, "^u+gh+$")             ~ "ugh",
    TRUE ~ interjection
  ))

# Also consolidate the first_co_word column the same way
all_interjections_raw <- all_interjections_raw %>%
  mutate(first_co_word = case_when(
    str_detect(first_co_word, "^[mh]+$")             ~ "mhm",
    first_co_word %in% c("uhhuh", "uhuh", "uhhum")  ~ "uhuh",
    first_co_word == "ahhah"                         ~ "aha",
    str_detect(first_co_word, "^u+h+m*$|^u+m+h*$")  ~ "um",
    str_detect(first_co_word, "^o+[hu]+m*$")         ~ "oh",
    str_detect(first_co_word, "^a+h+$")              ~ "ah",
    str_detect(first_co_word, "^hu+h*$")             ~ "huh",
    str_detect(first_co_word, "^u+h+o+h*$")          ~ "uh_oh",
    str_detect(first_co_word, "^o+ps+[ie]*$")        ~ "oops",
    str_detect(first_co_word, "^wo+w+$")             ~ "wow",
    str_detect(first_co_word, "^ye+a+h+$|^ya+h*$|^ye+h+$") ~ "yeah",
    str_detect(first_co_word, "^ye+s+$")             ~ "yes",
    str_detect(first_co_word, "^no+pe*$")            ~ "nope",
    str_detect(first_co_word, "^na+h+$")             ~ "nah",
    str_detect(first_co_word, "^sh+$")               ~ "shh",
    str_detect(first_co_word, "^e+w+$")              ~ "eww",
    str_detect(first_co_word, "^u+gh+$")             ~ "ugh",
    TRUE ~ first_co_word
  ))

# Step 2: Exclude non-interjections
exclude <- c(
  "right", "well", "so", "like", "alright", "okay", "you_know", "eh", "remember",
  "please", "sorry", "thank_you", "thanks",
  "look", "see", "say", "wait", "help",
  "my", "silly", "careful",
  "yyy", "xxx", "zzz"
)

# Step 3: Frequency table and whitelist
intj_freq <- all_interjections_raw %>%
  filter(!interjection %in% exclude) %>%
  count(interjection, sort = TRUE) %>%
  mutate(prop = n / sum(n),
         cum_prop = cumsum(prop))

intj_freq %>% print(n = 50)

whitelist <- intj_freq %>%
  filter(cum_prop <= 0.90 | lag(cum_prop, default = 0) < 0.90) %>%
  pull(interjection)

whitelist

# Step 4: Clean token-level data
all_interjections_both_clean <- all_interjections_raw %>%
  filter(interjection %in% whitelist)

# Step 5: Clean contingent interjections
contingent_interjections <- all_interjections_raw %>%
  filter(first_co_is_initial,
         first_co_word %in% whitelist,
         interjection %in% whitelist)
```


```{r aggregate }
# Utterances that contain at least one whitelisted interjection
clean_has_co <- all_interjections_both_clean %>%
  distinct(transcript_id, utterance_order) %>%
  mutate(has_co_clean = TRUE)

# Utterances where the first co-tagged word is whitelisted
clean_initial_co <- all_interjections_raw %>%
  filter(first_co_is_initial, first_co_word %in% whitelist) %>%
  distinct(transcript_id, utterance_order) %>%
  mutate(initial_co_clean = TRUE)

# Attach cleaned flags to utterances
all_utterances_clean <- all_utterances_raw %>%
  left_join(clean_has_co, by = c("transcript_id", "utterance_order")) %>%
  left_join(clean_initial_co, by = c("transcript_id", "utterance_order")) %>%
  mutate(has_co_clean = replace_na(has_co_clean, FALSE),
         initial_co_clean = replace_na(initial_co_clean, FALSE))

# Session-level summary
all_speakers_data <- all_utterances_clean %>%
  group_by(transcript_id) %>%
  mutate(session_length = n()) %>%
  ungroup() %>%
  group_by(transcript_id, corpus_name, target_child_name,
           age_months, SpeakerType) %>%
  summarise(
    total_utterances = n(),
    n_interjections  = sum(has_co_clean),
    session_length   = first(session_length),
    .groups = "drop"
  ) %>%
  mutate(PropIntrj = n_interjections / total_utterances)

# Contingency summary
contingency_data <- all_utterances_clean %>%
  filter(
    (SpeakerType == "non-CHI" & prev_speakertype == "CHI") |
    (SpeakerType == "CHI"     & prev_speakertype %in% c("non-CHI"))
  ) %>%
  group_by(transcript_id) %>%
  mutate(session_length = n()) %>%
  ungroup() %>%
  group_by(transcript_id, corpus_name, target_child_name,
           age_months, SpeakerType) %>%
  summarise(
    total_utterances = n(),
    n_initial_co     = sum(initial_co_clean),
    session_length   = first(session_length),
    .groups = "drop"
  ) %>%
  mutate(PropIntrj = n_initial_co / total_utterances)

# Caregiver summary
interjection_summary_clean <- all_speakers_data %>%
  filter(SpeakerType == "non-CHI") %>%
  rename(proportion = PropIntrj)
```



```{r save all rds, eval=FALSE}
saveRDS(all_utterances_raw,           "all_utterances_raw.rds")
saveRDS(all_interjections_both_clean, "all_interjections_both_clean.rds")
saveRDS(all_speakers_data,            "all_speakers_data.rds")
saveRDS(contingency_data,             "contingency_data.rds")
saveRDS(contingent_interjections,     "contingent_interjections.rds")
saveRDS(interjection_summary_clean,   "interjection_summary_clean.rds")
saveRDS(english_corpora,              "english_corpora.rds")
```


```{r total proportion of interjections}
interjection_summary_clean %>%
  filter(!is.na(age_months), age_months <= 72) %>%
  summarise(
    total_interjections = sum(n_interjections),
    total_utterances = sum(total_utterances),
    proportion = total_interjections / total_utterances
  )
```

#Analyses from here

```{r plot interjections by main caregiver}
role_codes <- c("MOT", "FAT", "DAD", "MOM", "INV", "SIS", "BRO", 
                "GRA", "GMA", "AUN", "UNC")

interlocutor_plot <- all_utterances_clean %>%
  filter(!is.na(age_months), age_months <= 72,
         SpeakerType == "non-CHI",
         speaker_code %in% role_codes) %>%
  mutate(speaker_code = recode(speaker_code, 
                                "DAD" = "FAT", 
                                "MOM" = "MOT")) %>%
  group_by(transcript_id, corpus_name, target_child_name,
           age_months, speaker_code) %>%
  summarise(
    total_utterances = n(),
    n_interjections  = sum(has_co_clean, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(PropIntrj = n_interjections / total_utterances) %>%
  group_by(speaker_code) %>%
  summarise(
    mean_proportion  = mean(PropIntrj),
    se               = sd(PropIntrj) / sqrt(n()),
    n_sessions       = n(),
    n_utterances     = sum(total_utterances),
    .groups = "drop"
  ) %>%
  arrange(desc(mean_proportion))

ggplot(interlocutor_plot, 
       aes(x = reorder(speaker_code, mean_proportion), 
           y = mean_proportion)) +
  geom_col(fill = "#2dd4bf", alpha = 0.8) +
  geom_errorbar(aes(ymin = mean_proportion - se, 
                    ymax = mean_proportion + se),
                width = 0.3, colour = "white") +
  geom_text(aes(label = paste0("n=", scales::comma(n_utterances))), 
            hjust = -0.2, size = 3, colour = "grey60") +
  coord_flip() +
  scale_y_continuous("Mean proportion of turns with interjection",
                     limits = c(0, 0.45)) +
  scale_x_discrete("Interlocutor") +
  theme_minimal(base_size = 13) +
  labs(title = "Caregiver interjection use by interlocutor",
       subtitle = "Children aged 0-72 months, English CHILDES corpora")
```


```{r regression models total turns with interjections }
# Fit model
all_speakers_data <- all_speakers_data %>%
  mutate(age_c = age_months - mean(age_months, na.rm = TRUE),
         session_length_s = scale(session_length))

model_quad <- lmer(PropIntrj ~ SpeakerType * poly(age_c, 3) + session_length_s + 
                     (1 | corpus_name/target_child_name), 
                   data = all_speakers_data)

summary(model_quad)

all_speakers_data <- all_speakers_data %>%
  mutate(SpeakerType = relevel(factor(SpeakerType), ref = "non-CHI"))

model_quad_releveled <- lmer(PropIntrj ~ SpeakerType * poly(age_c, 3) + session_length_s + 
                     (1 | corpus_name/target_child_name), 
                   data = all_speakers_data)

summary(model_quad_releveled)
```



```{r plot raw proportion of interjections by age and speaker type}
ggplot(all_speakers_data, 
       aes(x = age_months, y = PropIntrj, colour = SpeakerType)) +
  geom_point(alpha = 0.1, size = 0.3) +
  geom_smooth(method = "loess", se = TRUE, linewidth = 1.2) +
  scale_colour_manual(values = c("CHI" = "red", "non-CHI" = "blue")) +
  scale_x_continuous("Child age (months)") +
  scale_y_continuous("Proportion of turns with interjection") +
  theme_minimal(base_size = 13) +
  labs(title = "Interjection use by speaker type across development",
       subtitle = "English CHILDES corpora, 0-72 months",
       colour = "Speaker")
```

```{r plot model-estimated proportions of interjections}

pred <- ggpredict(model_quad, terms = c("age_c [all]", "SpeakerType"))

mean_age <- mean(all_speakers_data$age_months, na.rm = TRUE)
pred$age_months <- pred$x + mean_age

ggplot(all_speakers_data, aes(x = age_months, y = PropIntrj, colour = SpeakerType)) +
  geom_smooth(method = "loess", se = FALSE, linetype = "dashed", alpha = 0.3) +
  geom_line(data = pred, aes(x = age_months, y = predicted, colour = group), 
            inherit.aes = FALSE, linewidth = 1) +
  geom_ribbon(data = pred, aes(x = age_months, ymin = conf.low, ymax = conf.high, fill = group), 
              inherit.aes = FALSE, alpha = 0.2) +
  scale_colour_manual(name = "Speaker", values = c("CHI" = "red", "non-CHI" = "blue")) +
scale_fill_manual(name = "Speaker", values = c("CHI" = "red", "non-CHI" = "blue")) +
  theme_minimal(base_size = 13) +
  theme(plot.title = element_text(size = 11),
      plot.subtitle = element_text(size = 10)) +
  labs(x = "Age (months)", y = "Proportion interjections",
       title = "Model-estimated interjection use by speaker type across development",
       subtitle = "English CHILDES corpora before 2021, 0-72 months")

```


```{r 10 top interjections for adults and children}
# Get top 10 overall across both speaker types combined
top10_overall <- all_interjections_both_clean %>%
  filter(!is.na(age_months), age_months <= 72) %>%
  count(interjection, sort = TRUE) %>%
  slice_head(n = 10) %>%
  pull(interjection)

# Get counts for those interjections by speaker type
top10_combined <- all_interjections_both_clean %>%
  filter(!is.na(age_months), age_months <= 72,
         interjection %in% top10_overall) %>%
  mutate(SpeakerType = if_else(speaker_code == "CHI", "CHI", "non-CHI")) %>%
  group_by(SpeakerType, interjection) %>%
  summarise(n = n(), .groups = "drop")

ggplot(top10_combined,
       aes(x = reorder(interjection, n), y = n, fill = SpeakerType)) +
  geom_col(position = "dodge") +
  coord_flip() +
  scale_fill_manual(values = c("CHI" = "red", "non-CHI" = "blue")) +
  scale_y_continuous(labels = scales::comma) +
  xlab("Interjection") +
  ylab("Number of tokens") +
  theme_minimal(base_size = 13) +
  labs(title = "Top 10 interjections by speaker type",
       subtitle = "Children aged 0-72 months, English CHILDES corpora",
       fill = "Speaker")
```

```{r regression models contingent interjections}

# Fit model
contingency_data <- contingency_data %>%
  mutate(age_c = age_months - mean(age_months, na.rm = TRUE),
         session_length_s = scale(session_length))

model_contingency_cub <- lmer(PropIntrj ~ SpeakerType * poly(age_c, 3) + session_length_s + 
                     (1 | corpus_name/target_child_name), 
                   data = contingency_data)

summary(model_contingency_cub)

contingency_data <- contingency_data %>%
  mutate(SpeakerType = relevel(factor(SpeakerType), ref = "non-CHI"))

model_contingency_cub_releveled <- lmer(PropIntrj ~ SpeakerType * poly(age_c, 3) + session_length_s + 
                     (1 | corpus_name/target_child_name), 
                   data = contingency_data)

summary(model_contingency_cub_releveled)

```


```{r plot contingent interjections}
ggplot(contingency_data, 
       aes(x = age_months, y = PropIntrj, colour = SpeakerType)) +
  geom_point(alpha = 0.1, size = 0.3) +
  geom_smooth(method = "loess", se = TRUE, linewidth = 1.2) +
  scale_colour_manual(values = c("CHI" = "red", "non-CHI" = "blue")) +
  scale_x_continuous("Child age (months)") +
  scale_y_continuous("Proportion of contingent interjections") +
  theme_minimal(base_size = 13) +
  labs(title = "Turn-initial interjections following child utterances",
       subtitle = "English CHILDES corpora, 0-72 months",
       colour = "Speaker")
```

```{r plot model-estimated proportions of contingent interjections}

pred <- ggpredict(model_contingency_cub, terms = c("age_c [all]", "SpeakerType"))

mean_age <- mean(contingency_data$age_months, na.rm = TRUE)
pred$age_months <- pred$x + mean_age

ggplot(contingency_data, aes(x = age_months, y = PropIntrj, colour = SpeakerType)) +
  geom_smooth(method = "loess", se = FALSE, linetype = "dashed", alpha = 0.3) +
  geom_line(data = pred, aes(x = age_months, y = predicted, colour = group), 
            inherit.aes = FALSE, linewidth = 1) +
  geom_ribbon(data = pred, aes(x = age_months, ymin = conf.low, ymax = conf.high, fill = group), 
              inherit.aes = FALSE, alpha = 0.2) +
 scale_colour_manual(name = "Speaker", values = c("CHI" = "red", "non-CHI" = "blue")) +
scale_fill_manual(name = "Speaker", values = c("CHI" = "red", "non-CHI" = "blue")) +
  theme_minimal(base_size = 13) +
  theme(plot.title = element_text(size = 11),
      plot.subtitle = element_text(size = 10)) +
  scale_y_continuous(limits = c(NA, 0.4)) +
  labs(x = "Age (months)", y = "Proportion contingent interjections",
       title = "Model-estimated contingent interjection use by speaker type across development",
       subtitle = "English CHILDES corpora before 2021, 0-72 months")

```



```{r plot top 10 contingency interjections}
# Top 10 overall
top10_contingency <- contingent_interjections %>%
  filter(!is.na(age_months), age_months <= 72) %>%
  count(interjection, sort = TRUE) %>%
  slice_head(n = 10) %>%
  pull(interjection)

# Counts by speaker type
top10_contingency_combined <- contingent_interjections %>%
  filter(!is.na(age_months), age_months <= 72,
         interjection %in% top10_contingency) %>%
  group_by(SpeakerType, interjection) %>%
  summarise(n = n(), .groups = "drop")

ggplot(top10_contingency_combined,
       aes(x = reorder(interjection, n), y = n, fill = SpeakerType)) +
  geom_col(position = "dodge") +
  coord_flip() +
  scale_fill_manual(values = c("CHI" = "red", "non-CHI" = "blue")) +
  scale_y_continuous(labels = scales::comma) +
  xlab("Interjection") +
  ylab("Number of tokens") +
  theme_minimal(base_size = 13) +
  labs(title = "Top 10 contingent interjections by speaker type",
       subtitle = "Children aged 0-72 months, English CHILDES corpora",
       fill = "Speaker")
```
Elmlinger et al. (2019) showed that caregivers' contingent responses to children are simpler and more repetitive than non-contingent speech. A turn-initial interjection is about as simple as it gets — it's a single minimal response token that acknowledges the child's utterance before anything else.
Nearly 18% all caregiver responses to children open with an interjection. That fits perfectly with the Elmlinger framework and also connects to the robot application: if the robot needs processing time after a child utterance, deploying a turn-initial interjection like oh or yeah is exactly what a human caregiver would do in that position.

```{r plot to 5 non-CHI contingent interjections by age}
# Get the consolidated first_co_word for each utterance
first_co_lookup <- all_interjections_raw %>%
  filter(first_co_is_initial, first_co_word %in% whitelist) %>%
  distinct(transcript_id, utterance_order, first_co_word)

# Contingent non-CHI utterances with their initial interjection
contingent_initial <- all_utterances_clean %>%
  filter(SpeakerType == "non-CHI",
         prev_speakertype == "CHI",
         initial_co_clean) %>%
  left_join(first_co_lookup, by = c("transcript_id", "utterance_order"))

# Top 5
top5 <- contingent_initial %>%
  count(first_co_word, sort = TRUE) %>%
  slice_head(n = 5) %>%
  pull(first_co_word)

# Denominator: total contingent non-CHI utterances per transcript
contingent_nonchi_totals <- all_utterances_clean %>%
  filter(SpeakerType == "non-CHI", prev_speakertype == "CHI") %>%
  count(transcript_id, age_months, name = "n_contingent")

# Rate per transcript
top5_cont_by_age <- contingent_initial %>%
  filter(first_co_word %in% top5) %>%
  count(transcript_id, age_months, first_co_word, name = "n_initial") %>%
  left_join(contingent_nonchi_totals, by = c("transcript_id", "age_months")) %>%
  mutate(rate = n_initial / n_contingent)

# Plot
ggplot(top5_cont_by_age, aes(x = age_months, y = rate, colour = first_co_word)) +
  geom_smooth(method = "loess", se = FALSE) +
  labs(x = "Child age (months)",
       y = "Proportion of contingent non-CHI utterances",
       colour = "Interjection",
       title = "Top 5 non-CHI turn-initial interjections in contingent turns") +
  theme_minimal()
```
The pattern is interesting: yeah dominates with very young children (~25% of contingent turns) then drops sharply as children become more verbal. That's a pure acknowledgment/backchannel — caregivers saying "yeah" to pre-verbal babbling. As children start producing real utterances, caregivers shift to more substantive responses and the interjection types converge around 5-7%.
oh shows a slight U-shape — drops early, then rises again with older children. Possibly reflects a shift in function: from reactive ("oh!") with infants to epistemic marking ("oh, you mean...") with older children.
no holds steady around 5-6% throughout — consistent with it serving a regulatory function rather than a contingency device.
Good for the robot application: for younger children, lead with "yeah"; for older children, "oh" becomes more appropriate.

```{r plot to 5 CHI contingent interjections by age}
# Get the consolidated first_co_word for each utterance
first_co_lookup <- all_interjections_raw %>%
  filter(first_co_is_initial, first_co_word %in% whitelist) %>%
  distinct(transcript_id, utterance_order, first_co_word)

# Contingent CHI utterances with their initial interjection
contingent_initial_chi <- all_utterances_clean %>%
  filter(SpeakerType == "CHI",
         prev_speakertype %in% c("non-CHI"),
         initial_co_clean) %>%
  left_join(first_co_lookup, by = c("transcript_id", "utterance_order"))

# Top 5
top5_chi <- contingent_initial_chi %>%
  count(first_co_word, sort = TRUE) %>%
  slice_head(n = 5) %>%
  pull(first_co_word)

# Denominator: total contingent CHI utterances per transcript
contingent_chi_totals <- all_utterances_clean %>%
  filter(SpeakerType == "CHI",
         prev_speakertype %in% c("non-CHI")) %>%
  count(transcript_id, age_months, name = "n_contingent")

# Rate per transcript
top5_chi_by_age <- contingent_initial_chi %>%
  filter(first_co_word %in% top5_chi) %>%
  count(transcript_id, age_months, first_co_word, name = "n_initial") %>%
  left_join(contingent_chi_totals, by = c("transcript_id", "age_months")) %>%
  mutate(rate = n_initial / n_contingent)

# Plot
ggplot(top5_chi_by_age, aes(x = age_months, y = rate, colour = first_co_word)) +
  geom_smooth(method = "loess", se = FALSE) +
  labs(x = "Child age (months)",
       y = "Proportion of contingent CHI utterances",
       colour = "Interjection",
       title = "Top 5 CHI turn-initial interjections in contingent turns") +
  theme_minimal()
```
#What triggers interjections?
```{r compare interjection vs. no-interjection preceding utterances}
# What precedes and follows non-CHI contingent interjections?
contingent_context <- all_utterances_clean %>%
  arrange(transcript_id, utterance_order) %>%
  group_by(transcript_id) %>%
  mutate(
    next_speaker    = lead(SpeakerType),
    next_initial_co = lead(initial_co_clean),
    next_gloss      = lead(gloss),
    next_n_words    = lengths(str_split(lead(gloss), " "))
  ) %>%
  ungroup() %>%
  filter(SpeakerType == "CHI",
         next_speaker == "non-CHI") %>%
  mutate(
    # Properties of the CHILD utterance
    child_n_words      = lengths(str_split(gloss, " ")),
    child_unintellig   = str_detect(gloss, "\\bxxx\\b|\\byyy\\b"),
    child_one_word     = child_n_words == 1,
    child_question     = str_detect(gloss, "\\?"),
    # Properties of the CAREGIVER response
    intj_response      = next_initial_co,
    caregiver_n_words  = next_n_words,
    # Is the interjection the ENTIRE response?
    caregiver_only_intj = next_initial_co & caregiver_n_words == 1
  )

# Compare child utterances that DO vs DON'T trigger interjections
contingent_context %>%
  group_by(intj_response) %>%
  summarise(
    n = n(),
    mean_child_length     = mean(child_n_words, na.rm = TRUE),
    prop_unintelligible   = mean(child_unintellig, na.rm = TRUE),
    prop_one_word         = mean(child_one_word, na.rm = TRUE),
    mean_caregiver_length = mean(caregiver_n_words, na.rm = TRUE),
    prop_intj_only        = mean(caregiver_only_intj, na.rm = TRUE)
  ) %>%
  pivot_longer(-intj_response, names_to = "measure") %>%
  pivot_wider(names_from = intj_response, names_prefix = "intj_") %>%
  rename(no_intj = intj_FALSE, intj = intj_TRUE) %>%
  mutate(across(where(is.numeric), ~ round(.x, 3)))
```


```{r bridge pattern}
# Length of turns after interjection 
contingent_context %>%
  filter(intj_response, !caregiver_only_intj) %>%
  summarise(
    n = n(),
    mean_child_length     = mean(child_n_words, na.rm = TRUE),
    prop_unintelligible   = mean(child_unintellig, na.rm = TRUE),
    mean_caregiver_length = mean(caregiver_n_words, na.rm = TRUE)
  )

```
So the bridge pattern is: child says something relatively substantial or unintelligible → caregiver opens with interjection → follows with a longer-than-average response. That's scaffolding — the caregiver needs more processing time for a more complex response, and the interjection buys that time.
This is exactly the robot use case. The robot's workflow would be: child speaks → robot deploys "oh" or "yeah" → processes → delivers substantive response of ~5 words.

```{r compare interjection-only vs. interjection+words turs of non-CHI}
contingent_context %>%
  filter(intj_response) %>%
  mutate(response_type = if_else(caregiver_only_intj, 
                                  "intj_only", "intj_plus")) %>%
  group_by(response_type) %>%
  summarise(
    n = n(),
    mean_child_length     = mean(child_n_words, na.rm = TRUE),
    prop_unintelligible   = mean(child_unintellig, na.rm = TRUE),
    prop_one_word         = mean(child_one_word, na.rm = TRUE),
    mean_caregiver_length = mean(caregiver_n_words, na.rm = TRUE)
  ) %>%
  mutate(across(where(is.numeric), ~ round(.x, 3)))
```

Interjection-only follows shorter, more one-word child utterances. Interjection-plus follows longer child utterances. That's exactly what you'd predict: child says something brief → caregiver acknowledges with just "mhm" (nothing more to say). Child says something more substantive → caregiver opens with "oh" then continues with a real response.
This supports a dual-function account:

Interjection-only = contingency maintenance (child gave little to work with)
Interjection + continuation = processing bridge (child gave more, caregiver needs time to formulate)

Both are useful for the robot but for different reasons. Short/unintelligible child input → robot says "mhm" and waits. Longer child input → robot says "oh" while processing, then responds.

```{r single vs. multi-word interjections}
# Get caregiver contingent turns with their initial interjection
caregiver_contingent <- all_utterances_clean %>%
  filter(SpeakerType == "non-CHI",
         prev_speakertype == "CHI",
         initial_co_clean) %>%
  left_join(
    all_interjections_raw %>%
      filter(first_co_is_initial, first_co_word %in% whitelist) %>%
      distinct(transcript_id, utterance_order, first_co_word),
    by = c("transcript_id", "utterance_order")
  ) %>%
  filter(first_co_word %in% whitelist) %>%
  mutate(
    n_words = lengths(str_split(gloss, " ")),
    response_type = if_else(n_words == 1, "intj_only", "intj_plus")
  )

caregiver_contingent %>%
  count(first_co_word, response_type) %>%
  group_by(first_co_word) %>%
  mutate(total = sum(n),
         prop_only = n / total) %>%
  filter(response_type == "intj_only") %>%
  arrange(desc(total)) %>%
  select(first_co_word, total, n_only = n, prop_only) %>%
  mutate(prop_only = round(prop_only, 3))
```
```{r}
library(ggrepel)

intj_function <- caregiver_contingent %>%
  count(first_co_word, response_type) %>%
  group_by(first_co_word) %>%
  mutate(total = sum(n),
         prop_only = n / total) %>%
  filter(response_type == "intj_only") %>%
  ungroup()

ggplot(intj_function, aes(x = total, y = prop_only, label = first_co_word)) +
  geom_point() +
  geom_text_repel(size = 3) +
  labs(x = "Total contingent turn-initial uses",
       y = "Proportion standalone (interjection-only turns)",
       title = "Interjection frequency vs. standalone use in contingent turns") +
  theme_minimal()
```
The pattern is really clear:
"oh" is the bridge interjection — most frequent (75k uses) and standalone only 28% of the time. 72% of the time caregivers say "oh" and then continue with something else. That's WordMate's go-to processing bridge.
"mhm", "yeah", "yes", "no" are acknowledgment interjections — high frequency, standalone 60-80% of the time. Pure contingency maintenance.
"um" is never standalone (0%) — it's always a hesitation marker opening a longer turn. True filled pause.
"huh" is almost always standalone (~88%) — it's a repair initiator, not a bridge.
Nice functional taxonomy emerging just from this one variable. For WordMate we want two modes: acknowledgment mode (yeah/mhm, standalone) and bridge mode (oh/um + continuation).

